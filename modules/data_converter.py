"""
„Éá„Éº„ÇøÂ§âÊèõ„É¢„Ç∏„É•„Éº„É´
ÊôÇÈñìÂ§âÊèõ„ÄÅÂ∫ßÊ®ô„Éá„Éº„Çø„ÅÆÁµ±‰∏Ä„ÄÅ„Éá„Éº„ÇøÂûã„ÅÆÊ≠£Ë¶èÂåñ
"""

import pandas as pd
import numpy as np
from typing import List, Dict
from config import INPUT_TIMEZONE, OUTPUT_TIMEZONE, DEBUG


def convert_timestamp_to_utc(timestamp_str: str) -> pd.Timestamp:
    """„Çø„Ç§„É†„Çπ„Çø„É≥„ÉóÊñáÂ≠óÂàó„ÇíUTC„ÅÆnaive datetime„Å´Â§âÊèõ"""
    if not timestamp_str:
        return None
    try:
        dt = pd.to_datetime(timestamp_str, errors='coerce')
        if pd.isna(dt):
            return None
        # „Åæ„ÅöUTC„Å´ÊèÉ„Åà„Çã
        if dt.tz is None:
            dt = dt.tz_localize(OUTPUT_TIMEZONE)
        else:
            dt = dt.tz_convert(OUTPUT_TIMEZONE)
        # ÊúÄÂæå„Å´naiveÂåñ
        return dt.tz_localize(None)
    except Exception as e:
        if DEBUG:
            print(f"   ‚ö†Ô∏è ÊôÇÈñìÂ§âÊèõ„Ç®„É©„Éº: {timestamp_str!r} -> {e}")
        return None


def normalize_numeric_value(value) -> float:
    """Êï∞ÂÄ§„Éá„Éº„Çø„ÅÆÊ≠£Ë¶èÂåñ"""
    if value is None or value == '':
        return None
    
    try:
        return float(value)
    except (ValueError, TypeError):
        return None


def convert_records_to_dataframe(records: List[Dict]) -> pd.DataFrame:
    """„É¨„Ç≥„Éº„Éâ„É™„Çπ„Éà„ÇíDataFrame„Å´Â§âÊèõ„Åó„Å¶Ê≠£Ë¶èÂåñ"""
    if not records:
        return pd.DataFrame()
    
    df = pd.DataFrame(records)

    if DEBUG:
        print(f"   üîÑ {len(df)} „É¨„Ç≥„Éº„Éâ„ÇíÂ§âÊèõ‰∏≠...")
    
    # ÊôÇÈñì„Ç´„É©„É†„ÅÆÂ§âÊèõ
    time_columns = ['start_time', 'end_time', 'point_time']
    for col in time_columns:
        if col in df.columns:
            df[col] = df[col].apply(convert_timestamp_to_utc)
    
    # Êï∞ÂÄ§„Ç´„É©„É†„ÅÆÂ§âÊèõÔºàTimelineÁî®Ôºâ
    numeric_columns = [
        'latitude', 'longitude', 'activity_distanceMeters', 
        'visit_probability', 'activity_probability'
    ]
    
    # GPXÁî®„ÅÆËøΩÂä†Êï∞ÂÄ§„Ç´„É©„É†
    gpx_numeric_columns = [
        '_gpx_elevation', '_gpx_speed', '_gpx_point_sequence'
    ]
    
    all_numeric_columns = numeric_columns + gpx_numeric_columns
    
    for col in all_numeric_columns:
        if col in df.columns:
            df[col] = df[col].apply(normalize_numeric_value)
    
    # NaN „Çí None „Å´ÁΩÆÊèõ
    df = df.replace({np.nan: None})
    
    if DEBUG:
        print(f"   ‚úÖ „Éá„Éº„ÇøÂ§âÊèõÂÆå‰∫Ü")
    
    return df


def _to_naive_utc(series: pd.Series) -> pd.Series:
    """ÊñáÂ≠óÂàó/TimestampÊ∑∑Âú® ‚Üí UTC‚Üínaive‚Üídatetime64[ns] „Å∏Êï¥ÂΩ¢"""
    dt = pd.to_datetime(series, utc=True, errors="coerce")
    return dt.dt.tz_convert(None)


def sort_dataframe_by_time(df: pd.DataFrame) -> pd.DataFrame:
    """DataFrame„ÇíÊôÇÈñìÈ†Ü„Å´„ÇΩ„Éº„Éà"""
    if df.empty:
        return df

    if DEBUG:
        print("   üîÑ ÊôÇÈñìÈ†Ü„ÇΩ„Éº„Éà‰∏≠...")

    # „Åô„Åπ„Å¶„ÅÆÊôÇÈñìÂàó„ÇíUTC naive„Å™datetime64[ns]„Å´Áµ±‰∏Ä
    for col in ["point_time", "start_time", "end_time"]:
        if col in df.columns:
            df[col] = _to_naive_utc(df[col])

    # „ÇΩ„Éº„ÉàÁî®„ÅÆÊôÇÈñìÂàó„Çí‰ΩúÊàêÔºàÂÑ™ÂÖàÈ†Ü‰Ωç: point_time > start_time > end_timeÔºâ
    sort_time = df['point_time'].fillna(
        df['start_time'].fillna(df['end_time'])
    )

    # „ÇΩ„Éº„ÉàÂÆüË°å
    if not sort_time.isna().all():
        sorted_indices = sort_time.sort_values().index
        df_sorted = df.loc[sorted_indices].reset_index(drop=True)

        if DEBUG:
            print(f"   ‚úÖ ÊôÇÈñìÈ†Ü„ÇΩ„Éº„ÉàÂÆå‰∫Ü")

        return df_sorted
    else:
        if DEBUG:
            print("   ‚ö†Ô∏è „ÇΩ„Éº„ÉàÂèØËÉΩ„Å™ÊôÇÈñì„Éá„Éº„Çø„Å™„Åó")
        return df


def combine_dataframes(dataframes: List[pd.DataFrame]) -> pd.DataFrame:
    """Ë§áÊï∞„ÅÆDataFrame„ÇíÁµêÂêà"""
    if not dataframes:
        return pd.DataFrame()

    if DEBUG:
        total_records = sum(len(df) for df in dataframes)
        print(f"üîó {len(dataframes)}ÂÄã„ÅÆDataFrame„ÇíÁµêÂêà‰∏≠... (Á∑è{total_records}„É¨„Ç≥„Éº„Éâ)")
    
    combined_df = pd.concat(dataframes, ignore_index=True)

    if DEBUG:
        print(f"‚úÖ ÁµêÂêàÂÆå‰∫Ü: {len(combined_df)} „É¨„Ç≥„Éº„Éâ")
    
    return combined_df


def get_dataframe_summary(df: pd.DataFrame) -> Dict:
    """DataFrame„ÅÆË¶ÅÁ¥ÑÊÉÖÂ†±„ÇíÂèñÂæó"""
    if df.empty:
        return {"total_records": 0}

    _times = pd.concat([
        df.get("point_time"),
        df.get("start_time"),
        df.get("end_time")
    ])

    summary = {
        "total_records": len(df),
        "data_types": df['type'].value_counts().to_dict() if 'type' in df.columns else {},
        "users": df['username'].value_counts().to_dict() if 'username' in df.columns else {},
        "time_range": {
            "start": _times.min(),
            "end": _times.max(),
        },
        "location_records": df[['latitude', 'longitude']].notna().all(axis=1).sum() if all(col in df.columns for col in ['latitude', 'longitude']) else 0
    }

    # GPX„Éá„Éº„Çø„ÅÆÁâπÂà•Áµ±Ë®à
    gpx_data = df[df['type'].str.startswith('gpx', na=False)] if 'type' in df.columns else pd.DataFrame()
    if not gpx_data.empty:
        summary["gpx_stats"] = {
            "total_gpx_records": len(gpx_data),
            "gpx_data_sources": gpx_data['_gpx_data_source'].value_counts().to_dict() if '_gpx_data_source' in gpx_data.columns else {},
            "gpx_tracks": gpx_data['_gpx_track_name'].nunique() if '_gpx_track_name' in gpx_data.columns else 0,
            "elevation_range": {
                "min": gpx_data['_gpx_elevation'].min() if '_gpx_elevation' in gpx_data.columns else None,
                "max": gpx_data['_gpx_elevation'].max() if '_gpx_elevation' in gpx_data.columns else None
            } if '_gpx_elevation' in gpx_data.columns else None
        }

    return summary
